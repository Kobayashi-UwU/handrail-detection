{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO model and class labels\n",
    "net = cv2.dnn.readNet('yolov3.cfg', 'yolov3.weights')\n",
    "with open('coco.names', 'r') as f:\n",
    "    classes = f.read().strip().split('\\n')\n",
    "\n",
    "# Set confidence threshold and NMS threshold\n",
    "confidence_threshold = 0.5\n",
    "nms_threshold = 0.2\n",
    "\n",
    "# Open the video file (change the path to your video file)\n",
    "cap = cv2.VideoCapture('your_video.mp4')\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Skip frames and only process every 15th frame (2 frames per second)\n",
    "    if frame_count % 3 != 0:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (480, 270))\n",
    "\n",
    "    # Prepare the frame for YOLO object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "\n",
    "    # Initialize lists to store detected objects' information\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # Process detection results\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > confidence_threshold:\n",
    "                # YOLO returns bounding box coordinates as a fraction of the frame size\n",
    "                # Convert them to pixel coordinates\n",
    "                width, height = frame.shape[1], frame.shape[0]\n",
    "                x = int(detection[0] * width)\n",
    "                y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Calculate coordinates for drawing bounding box\n",
    "                x_min = int(x - w / 2)\n",
    "                y_min = int(y - h / 2)\n",
    "                x_max = int(x + w / 2)\n",
    "                y_max = int(y + h / 2)\n",
    "\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Perform Non-Maximum Suppression (NMS)\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, nms_threshold)\n",
    "\n",
    "    # Filter for detections labeled as 'person'\n",
    "    for i in indices:\n",
    "        class_id = class_ids[i]\n",
    "        if class_id < len(classes):\n",
    "            label = str(classes[class_id])\n",
    "\n",
    "            if label == 'person':\n",
    "                box = boxes[i]\n",
    "                x_min, y_min, x_max, y_max = box\n",
    "                confidence = confidences[i]\n",
    "\n",
    "                color = (0, 255, 0)  # BGR color for the bounding box (here, it's green)\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                cv2.putText(frame, f'{label} {confidence:.2f}', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Human Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Check for 'Esc' key (27)\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver 1\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"0UN03tALEnkf5kKTiWz1\")\n",
    "project = rf.workspace(\"camera-handrail-detection\").project(\"camera-handrail-detection\")\n",
    "dataset = project.version(7).download(\"coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver 2\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"0UN03tALEnkf5kKTiWz1\")\n",
    "project = rf.workspace(\"camera-handrail-detection\").project(\"camera-handrail-detection\")\n",
    "dataset = project.version(8).download(\"coco\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
